\documentclass{article}

\usepackage{hyperref}

\author{
  Reinier Maas \\ 4131495
  \and
  Adolfo Ochagav√≠a \\ 4045483
}
\title{CCO - Assignment 2}
\begin{document}

\maketitle

\section*{Modules}

\begin{itemize}
\item \texttt{Lexer and Parser}: there are no relevant modifications to these modules.
\item \texttt{Monotone}: implements the \texttt{mfp} function according to the slides of the course.
\item \texttt{AttributeGrammar}: see \textbf{Attribute Grammar}.
\item \texttt{ConstPropagation}: see \textbf{Constant Propagation}.
\item \texttt{StronglyLiveVariables}: see \textbf{Strongly Live Variables}.
\item \texttt{Main}: glues everything together in the \texttt{run} function (lexing, parsing, executing the attribute grammar, running the analyses and printing the results).
\end{itemize}

\section*{Building and running}

Provided you have \texttt{stack} and \texttt{uuagc} installed on your system, you can use \texttt{make} to build the project.
The project should probably build as well when using cabal, though we haven't tested it.
Below we explain how to actually run our code.

\subsubsection*{As a CLI tool}

After compiling the executable, you can run it using \texttt{stack exec mf <max-context-depth> <file>}.
This means that you should run the program specifying the max length of the context string and the relative path to the file you would like to analyze.
For instance, if your working directory is the root of the project, you could try the following: \texttt{stack exec mf 2 examples/cp1.c}.

If your run the executable and recieve the following error: \texttt{"argv" (line 1, column 1):unknown parse error}, the line endings in the QuasiQuoted part are \texttt{crlf} instead of \texttt{lf}.
Please update the \texttt{Main.hs} file to use \texttt{lf} line endings.

The results of the program are printed as a graph, specified in the DOT language.
Each analysis produces its own graph.
As you may already know, you can use GraphViz to actually get an image of the graph (or you can use \href{http://www.webgraphviz.com/}{this online version}).

Each time you run the program, the Constant Propagation and Strongly Live Variables analysis will be run.
Note that the latter is intraprocedural, so it will not be affected by changes to the \texttt{max-context-depth} parameter.
An excerpt of the output is shown below:

\begin{verbatim}
CP ANALYSIS:
digraph {
// Content replaced by this comment because of its length
}

SLV ANALYSIS:
digraph {
// Content replaced by this comment because of its length
}
\end{verbatim}

\subsubsection*{From GHCi}

Running the program from GHCi is almost the same as through the CLI application. While in the command line you need to execute \texttt{stack exec mf 2 examples/cp1.c}, in GHCi it is enough to write \texttt{run 2 "examples/cp1.c"}. In fact, the CLI is just a wrapper around the \texttt{run} function.

\section*{Features and assumptions}

% See https://github.com/aochagavia/CompilerConstruction/compare/mf-init...master for a diff

Assumption: no global variables.

\subsection*{Attribute Grammar}

Extensions:

\begin{itemize}
	\item \texttt{Program} to \texttt{Program'} transformation (labeling)
	\item CFG building: includes entry labels, exit labels. Basic support for error detection (e.g. \texttt{break} without a \texttt{while}).
\end{itemize}

\subsection*{MFP implementation}

A small note on our MFP implementation. Parameters:

\begin{itemize}
	\item nodes
	\item extremal labels
	\item extremal value
	\item transitions (edges)
	\item unary transfer function
	\item binary transfer function
	\item merge function
\end{itemize}

Nodes, transitions are obviously necessary. What about the rest? How do they interact with the algorithm?

\subsection*{Constant Propagation}

Interprocedural

How is the lattice defined?

How are the transfer functions defined?

Walkthrough

\subsection*{Strongly Live Variables}

Same questions as Constant Propagation

\end{document}
